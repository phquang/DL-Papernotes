Paper List
============

Generative Adversarial Networks (Last updated Nov 29, 2016)
-----------------------------------------------------------
1. Generative Adversarial Networks [[arXiv]](https://arxiv.org/pdf/1406.2661v1.pdf)
2. Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks [[arXiv]](https://arxiv.org/pdf/1506.05751.pdf)
3. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks [[arXiv]](https://arxiv.org/pdf/1511.06434v2.pdf)
4. Context Encoders: Feature Learning by Inpainting [[arXiv]](https://arxiv.org/pdf/1604.07379v2.pdf)
5. Coupled Generative Adversarial Networks [[arXiv]](https://arxiv.org/pdf/1606.07536.pdf)


RNN Regularization (Last updated Nov 29, 2016)
----------------------------------------------
1. A Simple Way to Initialize Recurrent Networks of Rectified Linear Units [[arXiv]](https://arxiv.org/pdf/1504.00941v2.pdf)
2. Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations [[arXiv]](https://arxiv.org/pdf/1606.01305v2.pdf)
3. Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks [[NIPS]](https://papers.nips.cc/paper/5956-scheduled-sampling-for-sequence-prediction-with-recurrent-neural-networks.pdf)
4. Semi-supervised Sequence Learning [[NIPS]](https://papers.nips.cc/paper/5949-semi-supervised-sequence-learning.pdf)
5. A Simple Way to Initialize Recurrent Networks of Rectified Linear Units [[arXiv]](https://arxiv.org/pdf/1504.00941.pdf)
6. Recurrent Neural Network Regularization [[arXiv]](https://arxiv.org/pdf/1409.2329.pdf)
7. Regularizing RNNs by Stabilizing Activations [[arXiv]](https://arxiv.org/pdf/1511.08400v7.pdf)

RNN Architectures (Last Updated Nov 29, 2016)
---------------------------------------------
1. Gated Recurrent Units [[arXiv]](https://arxiv.org/pdf/1406.1078v3.pdf), [[arXiv]](https://arxiv.org/pdf/1412.3555v1.pdf)
2. Grid Long-Short Term Memory [[arXiv]](https://arxiv.org/pdf/1507.01526v3.pdf)
3. Simplifying Long-Short term Memory Acoustic For Fast Training and Decoding [[Microsoft]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/lstm_simplification-1.pdf)
4. Recurrent Highway Networks [[arXiv]](https://arxiv.org/pdf/1607.03474v3.pdf)
5. Segmental Recurrent Neural Networks [[arXiv]](https://arxiv.org/pdf/1511.06018v2.pdf)
6. Sequential Neural Models with Stochastic Layers [[arXiv]](https://arxiv.org/pdf/1605.07571.pdf)
7. Learning Stochastic Recurrent Networks [[arXiv]](https://arxiv.org/pdf/1411.7610v3.pdf)
8. Unitary Evolution Recurrent Neural Networks [[JMLR]](http://jmlr.org/proceedings/papers/v48/arjovsky16.pdf)
9. Gated Feedback Recurrent Neural Networks [[arXiv]](https://arxiv.org/pdf/1502.02367.pdf)

RNN Training Algorithms (Last Updated Nov 29, 2016)
---------------------------------------------------
1. Training Recurrent Networks Online Without Backtracking [[arXiv]](https://arxiv.org/pdf/1507.07680v2.pdf)
2. Training Recurrent Neural Network by Diffusion [[arXiv]](https://arxiv.org/pdf/1601.04114v2.pdf)
3. How (not) to Train Your Generative Model: Scheduled Sampling, Likelihood, Adversary? [[arXiv]](https://arxiv.org/pdf/1511.05101.pdf)


