# Paper List
==========

## Iconic (Last Updated Nov 29, 2016)
- Building High-level Features Using Large Scale Unsupervised Learning [[arXiv]](https://arxiv.org/pdf/1112.6209.pdf)
- ImageNet Classification with Deep Convolutional Neural Networks [[NIPS]](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
- Dropout: A Simple Way to Prevent Neural Networks from Overfitting [[JMLR]](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)
- Long Short-Term Memory [[CMU]](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)

## Generative Adversarial Networks (Last updated Nov 29, 2016)
- Generative Adversarial Networks [[arXiv]](https://arxiv.org/pdf/1406.2661v1.pdf)
- Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks [[arXiv]](https://arxiv.org/pdf/1506.05751.pdf)
- Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks [[arXiv]](https://arxiv.org/pdf/1511.06434v2.pdf)
- Context Encoders: Feature Learning by Inpainting [[arXiv]](https://arxiv.org/pdf/1604.07379v2.pdf)
- Coupled Generative Adversarial Networks [[arXiv]](https://arxiv.org/pdf/1606.07536.pdf)
- SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient [[arXiv]](https://arxiv.org/pdf/1609.05473v4.pdf)
- GANs for Sequence of Discrete Elements with the Gumbel-softmax Distribution [[arXiv]](https://arxiv.org/pdf/1611.04051v1.pdf)
- Adversarial Autoencoders [[arXiv]](https://arxiv.org/pdf/1511.05644.pdf)
- Unsupervised and Semi-supervised Learning with Categorical Generative Adversarial Networks [[arXiv]](https://arxiv.org/pdf/1511.06390v2.pdf)
- Adversarial Training Methods for Semo-Supervised Text Classification [[arXiv]](https://arxiv.org/pdf/1605.07725v2.pdf)

## Regularization (Last updated Nov 29, 2016)
- A Simple Way to Initialize Recurrent Networks of Rectified Linear Units [[arXiv]](https://arxiv.org/pdf/1504.00941v2.pdf)
- Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations [[arXiv]](https://arxiv.org/pdf/1606.01305v2.pdf)
- Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks [[NIPS]](https://papers.nips.cc/paper/5956-scheduled-sampling-for-sequence-prediction-with-recurrent-neural-networks.pdf)
- Semi-supervised Sequence Learning [[NIPS]](https://papers.nips.cc/paper/5949-semi-supervised-sequence-learning.pdf)
- A Simple Way to Initialize Recurrent Networks of Rectified Linear Units [[arXiv]](https://arxiv.org/pdf/1504.00941.pdf)
- Recurrent Neural Network Regularization [[arXiv]](https://arxiv.org/pdf/1409.2329.pdf)
- Regularizing RNNs by Stabilizing Activations [[arXiv]](https://arxiv.org/pdf/1511.08400v7.pdf)
- Recurrent Batch Normalization [[arXiv]](https://arxiv.org/pdf/1603.09025.pdf)
- Layer Normalization [[arXiv]](https://arxiv.org/pdf/1607.06450.pdf)
- Dropout Training as Adaptive Regularization [[NIPS]](https://papers.nips.cc/paper/4882-dropout-training-as-adaptive-regularization.pdf)

## Architectures (Last Updated Nov 29, 2016)
### Convolutional Neural Networks
- Deeply-Fused Nets [[arXiv]](https://arxiv.org/pdf/1605.07716v1.pdf)
- FractalNet: Ultra-Deep Neural Networks Without Residuals [[arXiv]](https://arxiv.org/pdf/1605.07648v2.pdf)
- Higher Order Recurrent Networks [[arXiv]](https://arxiv.org/pdf/1605.00064v1.pdf)

### Recurrent Neural Networks
- Gated Recurrent Units [[arXiv]](https://arxiv.org/pdf/1406.1078v3.pdf), [[arXiv]](https://arxiv.org/pdf/1412.3555v1.pdf)
- Grid Long-Short Term Memory [[arXiv]](https://arxiv.org/pdf/1507.01526v3.pdf)
- Simplifying Long-Short term Memory Acoustic For Fast Training and Decoding [[Microsoft]](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/lstm_simplification-1.pdf)
- Recurrent Highway Networks [[arXiv]](https://arxiv.org/pdf/1607.03474v3.pdf)
- Segmental Recurrent Neural Networks [[arXiv]](https://arxiv.org/pdf/1511.06018v2.pdf)
- Sequential Neural Models with Stochastic Layers [[arXiv]](https://arxiv.org/pdf/1605.07571.pdf)
- Learning Stochastic Recurrent Networks [[arXiv]](https://arxiv.org/pdf/1411.7610v3.pdf)
- Unitary Evolution Recurrent Neural Networks [[JMLR]](http://jmlr.org/proceedings/papers/v48/arjovsky16.pdf)
- Gated Feedback Recurrent Neural Networks [[arXiv]](https://arxiv.org/pdf/1502.02367.pdf)
- HyperNetworks [[arXiv]](https://arxiv.org/pdf/1609.09106v3.pdf)
- Memory Networks [[arXiv]](https://arxiv.org/pdf/1410.3916v11.pdf)
- Hierarchical Memory Networks [[arXiv]](https://arxiv.org/pdf/1605.07427v1.pdf)
- Quasi-Recurrent Neural Networks [[arXiv]](https://arxiv.org/pdf/1611.01576v2.pdf)

## DL Theory (Last Updated Nov 29, 2016)
- A Mathematical Motivation for Complex-valued Convolutional Networks [[arXiv]](https://arxiv.org/pdf/1503.03438v3.pdf)
- A Probabilistic Theory of Deep Learning [[arXiv]](https://arxiv.org/pdf/1504.00641v1.pdf)
- A Theoretically Grounded Application of Dropout in Recurrent Neural Networks [[arXiv]](https://arxiv.org/pdf/1512.05287v5.pdf)
- Toward Deeper Understanding of Neural Networks: The Power of Initialization and a Dual View on Expressivity [[arXiv]](https://arxiv.org/pdf/1602.05897v1.pdf)
- Learning the Number of Neurons in Deep Networks [[NIPS]](http://papers.nips.cc/paper/6372-learning-the-number-of-neurons-in-deep-networks.pdf)
- A Theory of Generative ConvNet [[arXiv]](http://arxiv.org/pdf/1602.03264v3.pdf)
- The loss surface of Multilayer Nets [[arXiv]](https://arxiv.org/pdf/1412.0233v3.pdf)

## Training Algorithms (Last Updated Nov 29, 2016)
- Training Recurrent Networks Online Without Backtracking [[arXiv]](https://arxiv.org/pdf/1507.07680v2.pdf)
- Training Recurrent Neural Network by Diffusion [[arXiv]](https://arxiv.org/pdf/1601.04114v2.pdf)
- How (not) to Train Your Generative Model: Scheduled Sampling, Likelihood, Adversary? [[arXiv]](https://arxiv.org/pdf/1511.05101.pdf)

## Reinforcement Learning (Last Updated Nov 29, 2016)
- A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models [[arXiv]](https://arxiv.org/pdf/1611.03852v3.pdf)
- Neural Architecture Search with Reinforcement Learning [[arXiv]](https://arxiv.org/pdf/1611.01578v1.pdf)
- Reinforcement Learning with Unsupervised Auxiliary Tasks [[arXiv]](https://arxiv.org/pdf/1611.05397v1.pdf)

## Aplications (Last Updated Nov 29, 2016)
### Neural Language Modeling
- A Neural Probabilistic Language Model [[JMLR]](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
- Distributed Representation of Words and Phrases and their Compositionality [[NIPS]](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
- Character-level Convolutional Networks for Text Classification [[NIPS]](https://papers.nips.cc/paper/5782-character-level-convolutional-networks-for-text-classification.pdf)
- Character-Aware Neural Language Models [[arXiv]](https://arxiv.org/pdf/1508.06615.pdf)
- Skip-thought Vectors [[arXiv]](https://arxiv.org/pdf/1506.06726v1.pdf)
- Distributed Representations of Sentences and Documents [[arXiv]](https://arxiv.org/pdf/1405.4053v2.pdf)

### Video Action Recognition/Detection
- Learning Spatiotemporal Features with 3D Convolutional Networks [[arXiv]](https://arxiv.org/pdf/1412.0767.pdf)
- Two-Stream Convolutional Networks for Action Recognition in Videos [[arXiv]](https://arxiv.org/pdf/1406.2199.pdf)
- Convolutional Two-Stream Network Fusion for Video Action Recognition [[arXiv]](https://arxiv.org/pdf/1604.06573v2.pdf)
- End-to-end Learning of Action Detection from Frame Glimpses in Videos [[arXiv]](https://arxiv.org/pdf/1511.06984.pdf)
- Learning Temporal Embeddings for Complex Video Analysis [[arXiv]](https://arxiv.org/pdf/1505.00315v1.pdf)
- Action Recognition using Visual Attention [[arXiv]](https://arxiv.org/pdf/1511.04119v3.pdf)
- Dynamic Image Networks for Action Recognition [[Oxford]](https://www.robots.ox.ac.uk/~vgg/publications/2016/Bilen16a/bilen16a.pdf)
- Fusing Multi-Stream Deep Networks for Video Classification [[arXiv]](https://arxiv.org/pdf/1509.06086v2.pdf)

### Image Captioning
- Show and Tell: A Neural Image Caption Generator [[arXiv]](https://arxiv.org/pdf/1411.4555v2.pdf)
- Show, Attend and Tell: Neural Image Caption Generation with Visual Attention [[arXiv]](https://arxiv.org/pdf/1502.03044.pdf)
- DenseCap: Fully Convolutional Localization Networks for Dense Captioning [[arXiv]](https://arxiv.org/pdf/1511.07571v1.pdf)

### Visual Question Answering
- Generating Natural Questions About an Image [[ACL]](https://aclweb.org/anthology/P/P16/P16-1170.pdf)
- Neural Module Networks [[arXiv]](https://arxiv.org/pdf/1511.02799.pdf)
- Dynamic Memory Networks for Visual and Textual Question Answering [[JMLR]](http://jmlr.org/proceedings/papers/v48/xiong16.pdf)
- Stacked Attention Networks for Image Question Answering [[arXiv]](https://arxiv.org/pdf/1511.02274v2.pdf)
- Learning to Compose Neural Networks for Question Answering [[ACL]](http://www.aclweb.org/anthology/N16-1181)
- Ask Your Neurons: A Neural-based Approach to Answering Questions about Images [[arXiv]](https://arxiv.org/pdf/1505.01121v3.pdf)
- Exploring Models and Data for Image Question Answering [[arXiv]](https://arxiv.org/pdf/1505.02074v4.pdf)
- VQA: Visual Question Answering [[arXiv]](https://arxiv.org/pdf/1505.00468.pdf)
- Ask Me Anything: Free-form Visual Question Answering Based on Knowledge from External Sources [[arXiv]](https://arxiv.org/pdf/1511.06973.pdf)
- VisKE: Visual Knowledge Extraction and Question Answering by Visual Verification of Relation Phrases [[VISKE]](http://viske.cs.washington.edu/paper/fsadeghi_VisKE.pdf)
- Image Captioning and Visual Question Answering Based on Attributes and Their Related External Knowledge [[arXiv]](https://arxiv.org/pdf/1603.02814v1.pdf)


## Others (Last Updated Nov 29, 2016)
- Categorical Reparameterization with Gumbel-Softmax [[arXiv]](https://arxiv.org/pdf/1611.01144v2.pdf)
- Growing Recursive Self-Improvers [[IDSIA]](http://people.idsia.ch/~steunebrink/Publications/AGI16_growing_recursive_self-improvers.pdf)


